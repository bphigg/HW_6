---
title: "hw_6"
output: html_document
date: "2023-10-03"
---

```{r setup, include=FALSE}
library(dplyr)
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE, warnings = FALSE, error = FALSE)
```

## Overview

In this assignment we are going to conduct a t-test on a gamma distribution of a variety of shapes and determine the alpha rate (Type 1 errors) for each shape.  

## t-test

To get started, we will first need to write functions to conduct a t-test This will include a function to calculate the t-statistic and a function to compare that statistic to a t-distribution with a given significance level. Overall, we want to know if the mean of the gamma distribution falls within the distribution of the true mean (mu) for a given significance level.  

Calculate t-statistic
```{r t_stat}
t_stat <- function(data, mu){
  denom <- sd(data, na.rm = TRUE)/sqrt(length(data))
  numer <- (mean(data) - mu)
  return(numer/denom)
}
```
<br>
Once the t-statistic has been calculated, it will need to be compared to the t-distribution with specified significance levels. Determining whether the t-statistic falls within a t-distribution of mu also requires specifying the direction of the alternative hypothesis. To do this, we'll employ `ifelse()` function.
```{r t_test}
hyp_test <- function(t_stat, n, sig_level, direction){
  df <- n-1
  return(ifelse(direction == "left", return(t_stat <= qt(sig_level, df)),
                         ifelse(direction == "right", return(t_stat >= qt(1-sig_level, df)),
                                ifelse(direction == "two-sided", return(t_stat <= qt(sig_level/2, df) | t_stat >= qt(1-sig_level/2, df)),
                                       stop("enter direction ('left', right', two-sided')")))))
}
```
We've set up the logical operators to return `FALSE` if the t-statistic falls within the distribution of mu for the given significance level (null hypothesis NOT rejected) and to return `TRUE` if the t-statistic falls outside of the distribution of mu for the given significance level (null hypothesis IS rejected).
<br>

Lastly, a wrapper function is used to quickly run the hypothesis test with the given inputs of `data`, `mu`, `significance level` and `direction`.
```{r hyp_test_wrapper}
hyp_test_wrap <- function(data, mu, sig_level, direction){
  n <- length(data)
  df <- n-1
  t_stat <- t_stat(data, mu)
  test <- hyp_test(t_stat, n, sig_level, direction)
  return(test)
}
```
<br>

We can test this function on the `Iris` dataframe and check it's accuracy.
*Does the true mean of* `Sepal.Length` *differ from 5.5?*
```{r iris_testa}
# (mean(iris$Sepal.Length)-5.5)/(sd(iris$Sepal.Length)/sqrt(150)) = 5.078 
# qt(c(.05/2, 1-(.05/2)), 149) = -1.976, 1.976
# 5.078 <= -1.976 | 5.078 >= 1.976 -> TRUE
hyp_test_wrap(iris$Sepal.Length, 5.5, .05, "two-sided")
```
*Is the true mean of* `Sepal.Width` *greater than 3.5?*
```{r iris_testb}
# (mean(iris$Sepal.Width)-3.5)/(sd(iris$Sepal.Width)/sqrt(150)) = -12.439
# qt(1-.05, 149) = 1.655
# -12.439 >= 1.655 -> FALSE
hyp_test_wrap(iris$Sepal.Width, 3.5, .05, "right")
```
*Is the true mean of* `Petal.Length` *less than 4?*
```{r iris_testc}
# (mean(iris$Petal.Length)-4)/(sd(iris$Petal.Length)/sqrt(150)) = -1.679
# qt(.05, 149) = -1.655
# -1.679 <= -1.655 -> TRUE
hyp_test_wrap(iris$Petal.Length, 4, .05, "left")
```
<br>

## Monte Carlo

In this section, we want to compare the mean of a random gamma distribution to the actual mean (mu) of the distribution using a t-test. By using the significance levels of a t-distribution on the average of a gamma distribution, we will be able to calculate the Type 1 Error rate (alpha) and compare it to the expected error rate (significance level). In order to do this, we will need to be able to collect the results of a number, n,  of t-tests, each with a different gamma distribution. 

First we will create a function that will take in the parameters of a gamma distribution (size, shape, scale) as well as the parameters for the t-test (significance level, and direction of test). This function will then create a gamma distribution that will then run through the t-test returning a `TRUE` or `FALSE` result. This will tell us if the mean of the random gamma distribution is within the expected parameter (Null Hypothesis not rejected = `FALSE`) or the mean lies outside the expected parameter (Null Hypothesis is rejected = `TRUE`).
```{r gamma_test}
gamma_test <- function(size, shape, rate, alpha, direction){
  g_dist <- rgamma(size, shape, rate)
  mean <- shape*(1/rate)
  return(hyp_test_wrap(g_dist, mean, alpha, direction))
}
```
<br>
In this example, we'll create a gamma distribution of size 100, shape 2, rate 5, significance level .05, and "right-side" direction. The result of this test will tell us if the mean of the distribution is greater than mu, the expected mean. (mu here would be (shape * 1/scale) = 0.4)
```{r gamma_tes_1}
# using a seed to ensure the same result on each knit
set.seed(4)
gamma_test(100, 2, 5, .05, "right")
```
For this iteration of the gamma test, the mean of the distribution is less than the 95 percentile of the distribution of the expected mean, mu. Therefore we got the result `FALSE`, the Null Hypothesis is not rejected.
<br>
We can now run the `gamma_test()` function through the `replicate` function n times to get the results of n different gamma distributions. 
```{r gamma_replicates}
set.seed(NULL)
replicate(10, gamma_test(10, .2, 1, .05, "two-sided"), simplify="array")
```
<br>
Wrap this in a `mean()` function and we get the average number of times the mean of a gamma distribution exceeds the significance level. Let's run the gamma test on 10,000 gamma distributions and get the average Null Hypothesis rejections.
```{r gamma_mean}
set.seed(4)
mean(replicate(10000, gamma_test(10, .2, 1, .05, "two-sided"), simplify="array"))
```
Here we can see the average rate at which the mean of the gamma distribution was statistically significant (the Type I Error Rate, since we know mu is the correct mean) is 23.23%. This is over four times higher than expected with a significance level of .05.
(**Rember** we're expecting a high error rate because we are comparing the results of a gamma distribution to the significance level of a t-distribution).
<br>
## Parallel Computing
<br>
In the previous Monte Carlo scenario, we were able to reproduce and record the results of the `gamma_test()` 10,000 times. But to do so, we had to use the same parameters for the gamma distribution. Now lets see if we can do the same test with different parameters and compare the results.

To make things a little easier, we set the scale to 1, making the actual mean of the gamma distribution equal the shape of the distribution. Next, we'll decide that we'll use a significance value of `0.5` and the test direction `two-sided.` This narrows down the parameters in the `gamma_test()` function to two inputs - shape and size of the distribution.  

Here's the updated `gamma_test()` function.
```{r gamma_test_p}
# created slightly new name to differentiate it from the 5 parameter function
gamma_test_p <- function(size, shape, rate = 1){
  g_dist <- rgamma(size, shape, rate)
  mean <- shape*(1/rate)
  # hard coded significance level and test direction
  return(hyp_test_wrap(g_dist, mean, .05, "two-sided"))
}
```
<br>
Now we'll create two vectors - one for the varying size parameter and another for the varying shape parameter. We'll combine the two vectors into a dataframe with each row equal to 1 of the 35 combinations.
```{r size_shape_parameters}
size <- c(10, 20, 30, 40, 50)
shape <- c(.2, .5, 1, 2, 5, 10, 20)
par_list <- expand.grid(size=size, shape=shape)
head(par_list)
```
<br>
Next, we'll convert the `par_list` dataframe to a list using `lapply()`. This will enable us to iterate over all the combinations of size and shape to create our gamma distributions.
```{r par_list_lapply}
parameters <- lapply(1:35, FUN = function(x){as.list(par_list[x, ])})
parameters[[1]]
```
<br>
We'll also need a quick wrapper function that will be able to take in the iterations of the `lapply()` function. This will 'funnel' the `lapply()` iterations to the `mean(replicate())` function we created earlier. Whereas before we entered the gamma distribution parameters manually, here we set up the size and shape parameters to be automatically derived from the `parameters` list we created above.
```{r wrapper_mean(replicate())}
get_results <- function(x){
  #  replication number is 10 so we can do a quick test
  mean(replicate(10, gamma_test_p(parameters[[x]][[1]], parameters[[x]][[2]], rate = 1)))
}
```
<br>
Let's use `lapply()` again and generate 35 Type I Error rates for each gamma parameter. Each parameter will be run 10 times.
```{r test_1}
results <- lapply(1:35, FUN=get_results)
unlist(results)
```
<br>
Great! Now let's transform the data into a readable format. Each of the 35 results corresponds to one of the parameter combinations. Since the iteration was sequential, we know that the index of the results corresponds to the index of the `parameters` list. So we'll unpack the `parameters` list and create a dataframe with the resulting size and shape columns along with the results column.
```{r create results_df}
pars_size <- lapply(1:35, FUN = function(x){parameters[[x]][1]})
pars_shape <- lapply(1:35, FUN = function(x){parameters[[x]][2]})
results_df <- tibble(shape = unlist(pars_shape), size = unlist(pars_size), results = unlist(results))
results_df %>% pivot_wider(names_from = "size", values_from = "results")
```
<br>
Now that everything is set up and working. Let's go ahead and set up the Parallel Computing codes so we can run our analysis 10,000 times for each of the 35 combinations of gamma parameters.

First, we'll update our `get_results()` function to 10,000 replications.
```{r get_results_10000}
get_results_ <- function(x){
  mean(replicate(10000, gamma_test_p(parameters[[x]][[1]], parameters[[x]][[2]], rate = 1)))
}
```
<br>
Next the parallel settings.
```{r parallel_set_up, results="hide"}
library(parallel)
cores <- detectCores()
cluster <- makeCluster(cores - 1)
clusterExport(cluster, list("get_results_", "gamma_test_p", "hyp_test_wrap", "hyp_test", "t_stat", "parameters", "par_list", "size", "shape"))
clusterEvalQ(cluster, library(dplyr))
clusterEvalQ(cluster, library(tidyverse))
```
<br>
Finally, we'll run `parLapply()` on the analysis and `unlist()` the results to spot check.
```{r parallel_run}
results_par <- parLapply(cluster, 1:35, fun=get_results_)
unlist(results_par)
```
<br>
Great! Finally, we'll convert our results to a dataframe.
```{r pivot_results}
temp <- tibble(shape = unlist(pars_shape), size = unlist(pars_size), results = unlist(results_par))
temp %>% pivot_wider(names_from = "size", values_from = "results")
```

